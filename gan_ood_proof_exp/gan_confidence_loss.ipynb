{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Implementing training confidence calibrated classifier paper for synthetic data experiment \"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Activation, Lambda\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "# for reproducibility \n",
    "np.random.seed(1)\n",
    "set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GAN(object):\n",
    "\n",
    "    \"\"\" Generative Adversarial Network class \"\"\"\n",
    "    def __init__(self):\n",
    "\n",
    "\n",
    "        self.number_of_classes = 2\n",
    "        self.input_dim = 2\n",
    "        self.gen_input_dim = 100\n",
    "        self.epochs = 20000\n",
    "        self.batch_size = 200\n",
    "        self.save_interval = 100\n",
    "        # There are 2 inlier circles\n",
    "        # Inlier circle centers on the 1st axis; for all other dimensions, the centers are at 0.\n",
    "        self.x1 = 0.3\n",
    "        self.x2 = 0.6\n",
    "        self.r = 0.1\n",
    "        # Number of inlier samples for each class\n",
    "        self.n = 1000\n",
    "        # width of the outlier outer square side\n",
    "        self.s = 100\n",
    "\n",
    "        # Confidence loss weight\n",
    "        self.beta_G = 1.0\n",
    "        self.beta_C = 0.5\n",
    "        # get in-distribution data from 2 circles (2 classes)\n",
    "        self.data, self.labels = self.get_data()\n",
    "\n",
    "        print(self.data.shape, self.labels.shape)\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.data, self.labels, test_size=0.5, shuffle=True, stratify=self.labels,\n",
    "                                                            random_state=1)\n",
    "\n",
    "        self.Y_train = np_utils.to_categorical(self.y_train, self.number_of_classes)\n",
    "        self.Y_test = np_utils.to_categorical(self.y_test, self.number_of_classes)\n",
    "\n",
    "        self.optimizer = Adam(lr=0.0002, beta_1=0.5, decay=8e-8)\n",
    "\n",
    "        self.G = self.__generator()\n",
    "        self.G.compile(loss='binary_crossentropy', optimizer=self.optimizer)\n",
    "\n",
    "        self.D = self.__discriminator()\n",
    "        self.D.compile(loss='binary_crossentropy', optimizer=self.optimizer, metrics=['accuracy'])\n",
    "\n",
    "        self.C = self.__classifier()\n",
    "        self.C.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5, decay=1e-4), metrics=['accuracy'])\n",
    "\n",
    "        self.stacked_generator_discriminator_classifier = self.__stacked_generator_discriminator_classifier()\n",
    "        self.stacked_generator_discriminator_classifier.compile(loss={'out_d':'binary_crossentropy', 'out_c':'categorical_crossentropy'}, \n",
    "                                       loss_weights={'out_d': 1.0, 'out_c': self.beta_G}, optimizer=self.optimizer, \n",
    "                                       metrics={'out_d':['acc'], 'out_c':['categorical_crossentropy']})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # return True if point p (a list) lies inside a hypersphere centered at the origin with radius r\n",
    "    def is_in_hypersphere(self, r, p):\n",
    "        p = np.array(p)\n",
    "        return np.sum(p*p) <= r**2\n",
    "\n",
    "\n",
    "    # return True if point p (a list) lies inside a hypersphere centered at the (x, 0, 0, ...) with radius r\n",
    "    def is_in_hypersphere_centered_at(self, x, r, p):\n",
    "        p = np.array(p)\n",
    "        p[0] -= x\n",
    "        return np.sum(p*p) <= r**2\n",
    "\n",
    "\n",
    "    # uniformly sample a point from a square centered at the origin with side = s\n",
    "    def sample_point_from_square(self, s):\n",
    "        p = []\n",
    "        # first point\n",
    "        for i in range(0, self.input_dim):\n",
    "            p.append(np.random.uniform(-1*s/2, s/2, 1))\n",
    "        return p\n",
    "\n",
    "\n",
    "    # sample points using rejection sampling from a sphere centered at the origin\n",
    "    def sample_point_from_hypersphere(self, r):\n",
    "        p = self.sample_point_from_square(2*r)\n",
    "        while not self.is_in_hypersphere(r, p):\n",
    "            p = self.sample_point_from_square(2*r)\n",
    "        return p\n",
    "            \n",
    "\n",
    "    # sample from a hypersphre with rejection sampling\n",
    "    def get_hypersphere_data(self, x, r, n):\n",
    "        data = np.zeros((n, self.input_dim))\n",
    "        count = 0\n",
    "        while count<n:\n",
    "            data[count, :] = self.sample_point_from_hypersphere(r)\n",
    "            # update the point with offset for the 1st dimension\n",
    "            data[count, 0] += x\n",
    "            count += 1\n",
    "\n",
    "        data = data.astype(np.float32)\n",
    "        return data\n",
    "        # plt.scatter(x, y, s = 4)\n",
    "    \n",
    "    \n",
    "    def get_data(self):\n",
    "        # class 0 data\n",
    "        data = self.get_hypersphere_data(self.x1, self.r, self.n)\n",
    "        labels = np.ones((self.n, 1))*0\n",
    "        print(labels.shape)\n",
    "        # class 1 data\n",
    "        data = np.concatenate((data, self.get_hypersphere_data(self.x2, self.r, self.n)), axis=0)\n",
    "        labels = np.concatenate((labels, np.ones((self.n, 1))*1), axis=0)\n",
    "        print(labels.shape)\n",
    "\n",
    "        return data.astype(np.float32), labels.astype(np.float32)\n",
    "\n",
    "\n",
    "    def __generator(self):\n",
    "        \"\"\" Declare generator \"\"\"\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(256, input_shape=(self.gen_input_dim,)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        #model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        #model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        #model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(self.input_dim, activation='linear'))\n",
    "\n",
    "        return model\n",
    "\n",
    "    def __discriminator(self):\n",
    "        \"\"\" Declare discriminator \"\"\"\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(256, input_shape=(self.input_dim, )))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    def __generator(self):\n",
    "        # Declare generator \n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(500, input_shape=(self.gen_input_dim,)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(self.input_dim, activation='linear'))\n",
    "\n",
    "        return model\n",
    "\n",
    "    def __discriminator(self):\n",
    "        # Declare discriminator\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(500, input_shape=(self.input_dim, )))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "    \"\"\"\n",
    "\n",
    "    def __classifier(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(500, input_shape=(self.input_dim,)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(self.number_of_classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def __stacked_generator_discriminator_classifier(self):\n",
    "        self.D.trainable = False\n",
    "        self.C.trainalble = False\n",
    "\n",
    "        # generator input\n",
    "        in_g = Input(shape=(self.gen_input_dim, ))\n",
    "        # generator output\n",
    "        out_g = self.G(in_g)\n",
    "\n",
    "        # discriminator output\n",
    "        out_d = self.D(out_g)\n",
    "        # classifier output\n",
    "        out_c = self.C(out_g)\n",
    "\n",
    "        out_d = Lambda(lambda x: x, name = 'out_d')(out_d)\n",
    "        out_c = Lambda(lambda x: x, name = 'out_c')(out_c)\n",
    "\n",
    "        model = Model(inputs=[in_g], outputs=[out_d, out_c])\n",
    "        return model\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # gen_data = np.empty((self.epochs*10, self.input_dim))\n",
    "        # count = 0\n",
    "        y_discriminator_ones = np.ones((self.batch_size/2, 1)).astype(np.float32)\n",
    "        y_discriminator_zeros = np.zeros((self.batch_size/2, 1)).astype(np.float32)\n",
    "        y_out = np.ones((self.batch_size/2, 2)).astype(np.float32)\n",
    "        sample_weight = np.ones((self.batch_size)).astype(np.float32)\n",
    "        sample_weight[self.batch_size/2:] = self.beta_C\n",
    "\n",
    "        for cnt in range(self.epochs):\n",
    "\n",
    "            ## train discriminator\n",
    "            random_index = np.random.randint(0, len(self.X_train) - self.batch_size/2)\n",
    "            legit_images = self.X_train[random_index : random_index + self.batch_size/2]\n",
    "\n",
    "            gen_noise = np.random.normal(0, 1, (self.batch_size/2, self.gen_input_dim))\n",
    "            synthetic_images = self.G.predict(gen_noise)\n",
    "\n",
    "            x_combined_batch = np.concatenate((legit_images, synthetic_images))\n",
    "            y_combined_batch = np.concatenate((y_discriminator_ones, y_discriminator_zeros))\n",
    "\n",
    "            d_loss = self.D.train_on_batch(x_combined_batch, y_combined_batch)\n",
    "\n",
    "            \"\"\"\n",
    "            gen_noise = np.random.normal(0, 1, (100, 100))\n",
    "            syntetic_images = self.G.predict(gen_noise)\n",
    "            preds = self.D.predict(syntetic_images)\n",
    "            ind = np.where(preds < self.thresh)[0]\n",
    "            if len(ind) > 0:\n",
    "                gen_data[count:count+min(10, ind.shape[0]),] = syntetic_images[ind[0:min(10, ind.shape[0])],]\n",
    "                count = count + min(10, ind.shape[0])\n",
    "            \"\"\"\n",
    "\n",
    "            # train generator\n",
    "            noise = np.random.normal(0, 1, (self.batch_size/2, self.gen_input_dim))\n",
    "            g_loss = self.stacked_generator_discriminator_classifier.train_on_batch([noise], [y_discriminator_ones, y_out])\n",
    "\n",
    "            # train classifier\n",
    "            random_index = np.random.randint(0, len(self.X_train) - self.batch_size/2)\n",
    "            legit_images = self.X_train[random_index : random_index + self.batch_size/2]\n",
    "            legit_labels = self.Y_train[random_index : random_index + self.batch_size/2]\n",
    "\n",
    "            gen_noise = np.random.normal(0, 1, (self.batch_size/2, self.gen_input_dim))\n",
    "            synthetic_images = self.G.predict(gen_noise)\n",
    "\n",
    "            x_combined_batch = np.concatenate((legit_images, synthetic_images))\n",
    "            y_combined_batch = np.concatenate((legit_labels, y_out))\n",
    "\n",
    "            c_loss = self.C.train_on_batch(x_combined_batch, y_combined_batch, sample_weight=sample_weight)\n",
    "            #print ('epoch: %d, [Discriminator :: d_loss: %f], [ Generator :: loss: %f], [ Classifier :: loss: %f]' % \n",
    "            #       (cnt, d_loss[0], g_loss, 10.1))\n",
    "\n",
    "            if cnt % self.save_interval == 0:\n",
    "                print('epoch: %d' % cnt)\n",
    "                print(\"d_loss\", d_loss)\n",
    "                print(\"g_loss\", g_loss)\n",
    "                c_loss = self.C.evaluate(self.X_test, self.Y_test)\n",
    "                print(\"c_loss:\", c_loss)\n",
    "                self.plot_data(save2file=True, step=cnt)\n",
    "\n",
    "\n",
    "\n",
    "    def plot_data(self, save2file, step=0):\n",
    "        ''' Plot and generated images '''\n",
    "\n",
    "        gen_noise = np.random.normal(0, 1, (self.X_test.shape[0], self.gen_input_dim))\n",
    "        synthetic_images = self.G.predict(gen_noise)\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(5,5))\n",
    "        ind = np.where(self.y_test == 0)[0]\n",
    "        plt.scatter(self.X_test[ind, 0], self.X_test[ind, 1], s=10, c='r', marker='D')\n",
    "        ind = np.where(self.y_test == 1)[0]\n",
    "        plt.scatter(self.X_test[ind, 0], self.X_test[ind, 1], s=10, c='b', marker='o')\n",
    "        plt.scatter(synthetic_images[:, 0], synthetic_images[:, 1], s=10, c='y', marker='*')\n",
    "        plt.legend(('$class\\ 0$','$class\\ 1$','$OOD\\ sample$'), fontsize='x-small');\n",
    "\n",
    "        if save2file:\n",
    "            filename = \"./images/mnist_%d.png\" % step\n",
    "            plt.savefig(filename)\n",
    "        plt.close('all')\n",
    "        #plt.show()\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n",
      "(2000, 1)\n",
      "((2000, 2), (2000, 1))\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_330 (Dense)            (None, 256)               768       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_142 (LeakyReLU)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_331 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_143 (LeakyReLU)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_332 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_144 (LeakyReLU)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_333 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 132,609\n",
      "Trainable params: 132,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "epoch: 0\n",
      "('d_loss', [0.69026154, 0.775])\n",
      "('g_loss', [2.0903041, 0.7036234, 1.3866807, 0.05, 1.3866807])\n",
      "1000/1000 [==============================] - 6s 6ms/step\n",
      "('c_loss:', [0.6849201250076294, 0.5])\n",
      "epoch: 100\n",
      "('d_loss', [0.6731801, 0.64])\n",
      "('g_loss', [2.1608515, 0.77329654, 1.3875549, 0.12, 1.3875549])\n",
      "1000/1000 [==============================] - 0s 67us/step\n",
      "('c_loss:', [0.6540068979263306, 0.82])\n",
      "epoch: 200\n",
      "('d_loss', [0.6946062, 0.485])\n",
      "('g_loss', [2.0694747, 0.68132323, 1.3881514, 0.87, 1.3881514])\n",
      "1000/1000 [==============================] - 0s 77us/step\n",
      "('c_loss:', [0.613364185333252, 0.895])\n",
      "epoch: 300\n",
      "('d_loss', [0.6928583, 0.495])\n",
      "('g_loss', [2.0745642, 0.68557626, 1.3889879, 0.98, 1.3889879])\n",
      "1000/1000 [==============================] - 0s 72us/step\n",
      "('c_loss:', [0.5987375993728637, 1.0])\n",
      "epoch: 400\n",
      "('d_loss', [0.6935068, 0.285])\n",
      "('g_loss', [2.086122, 0.69672424, 1.3893977, 0.0, 1.3893977])\n",
      "1000/1000 [==============================] - 0s 83us/step\n",
      "('c_loss:', [0.5952838025093079, 0.936])\n",
      "epoch: 500\n",
      "('d_loss', [0.6909615, 0.515])\n",
      "('g_loss', [2.0813048, 0.6920488, 1.389256, 0.6, 1.389256])\n",
      "1000/1000 [==============================] - 0s 78us/step\n",
      "('c_loss:', [0.5573271102905274, 1.0])\n",
      "epoch: 600\n",
      "('d_loss', [0.6924945, 0.5])\n",
      "('g_loss', [2.1048615, 0.71220595, 1.3926556, 0.0, 1.3926556])\n",
      "1000/1000 [==============================] - 0s 64us/step\n",
      "('c_loss:', [0.5282624289989472, 1.0])\n",
      "epoch: 700\n",
      "('d_loss', [0.645084, 0.57])\n",
      "('g_loss', [2.4524555, 1.0594234, 1.393032, 0.0, 1.393032])\n",
      "1000/1000 [==============================] - 0s 97us/step\n",
      "('c_loss:', [0.5486268353462219, 0.538])\n",
      "epoch: 800\n",
      "('d_loss', [0.66140336, 0.935])\n",
      "('g_loss', [2.1232483, 0.72461104, 1.3986373, 0.06, 1.3986373])\n",
      "1000/1000 [==============================] - 0s 74us/step\n",
      "('c_loss:', [0.38445278668403626, 1.0])\n",
      "epoch: 900\n",
      "('d_loss', [0.673945, 0.585])\n",
      "('g_loss', [2.195833, 0.8059396, 1.3898933, 0.0, 1.3898933])\n",
      "1000/1000 [==============================] - 0s 63us/step\n",
      "('c_loss:', [0.48382985639572146, 0.85])\n",
      "epoch: 1000\n",
      "('d_loss', [0.69715196, 0.525])\n",
      "('g_loss', [2.1326096, 0.7399299, 1.3926797, 0.0, 1.3926797])\n",
      "1000/1000 [==============================] - 0s 65us/step\n",
      "('c_loss:', [0.4801283707618713, 0.62])\n",
      "epoch: 1100\n",
      "('d_loss', [0.71644455, 0.255])\n",
      "('g_loss', [2.1041765, 0.70454925, 1.3996272, 0.3, 1.3996272])\n",
      "1000/1000 [==============================] - 0s 61us/step\n",
      "('c_loss:', [0.4500277364253998, 0.694])\n",
      "epoch: 1200\n",
      "('d_loss', [0.6999727, 0.235])\n",
      "('g_loss', [2.0746088, 0.66209793, 1.4125109, 0.83, 1.4125109])\n",
      "1000/1000 [==============================] - 0s 67us/step\n",
      "('c_loss:', [0.36097574067115784, 1.0])\n",
      "epoch: 1300\n",
      "('d_loss', [0.63066274, 0.76])\n",
      "('g_loss', [2.189395, 0.7863023, 1.4030925, 0.0, 1.4030925])\n",
      "1000/1000 [==============================] - 0s 62us/step\n",
      "('c_loss:', [0.3106379113197327, 0.933])\n",
      "epoch: 1400\n",
      "('d_loss', [0.6839766, 0.7])\n",
      "('g_loss', [2.1327662, 0.73187524, 1.4008911, 0.0, 1.4008911])\n",
      "1000/1000 [==============================] - 0s 61us/step\n",
      "('c_loss:', [0.3317555260658264, 0.998])\n",
      "epoch: 1500\n",
      "('d_loss', [0.6700956, 0.35])\n",
      "('g_loss', [2.0874193, 0.6857386, 1.4016807, 0.73, 1.4016807])\n",
      "1000/1000 [==============================] - 0s 70us/step\n",
      "('c_loss:', [0.5438596014976501, 0.513])\n",
      "epoch: 1600\n",
      "('d_loss', [0.6655491, 0.66])\n",
      "('g_loss', [2.1655412, 0.76944304, 1.396098, 0.0, 1.396098])\n",
      "1000/1000 [==============================] - 0s 61us/step\n",
      "('c_loss:', [0.23773368096351624, 1.0])\n",
      "epoch: 1700\n",
      "('d_loss', [0.60570514, 0.765])\n",
      "('g_loss', [2.2754753, 0.87252814, 1.4029472, 0.0, 1.4029472])\n",
      "1000/1000 [==============================] - 0s 62us/step\n",
      "('c_loss:', [0.25848729825019834, 0.97])\n",
      "epoch: 1800\n",
      "('d_loss', [0.621785, 0.415])\n",
      "('g_loss', [2.0654123, 0.65938765, 1.4060246, 0.88, 1.4060246])\n",
      "1000/1000 [==============================] - 0s 70us/step\n",
      "('c_loss:', [0.29355835151672366, 0.979])\n",
      "epoch: 1900\n",
      "('d_loss', [0.52754617, 0.89])\n",
      "('g_loss', [2.1368172, 0.7425738, 1.3942435, 0.0, 1.3942435])\n",
      "1000/1000 [==============================] - 0s 61us/step\n",
      "('c_loss:', [0.37179620933532714, 0.792])\n",
      "epoch: 2000\n",
      "('d_loss', [0.7175601, 0.5])\n",
      "('g_loss', [2.2569733, 0.85464805, 1.4023253, 0.0, 1.4023253])\n",
      "1000/1000 [==============================] - 0s 62us/step\n",
      "('c_loss:', [0.3606645364761353, 0.942])\n",
      "epoch: 2100\n",
      "('d_loss', [0.7063465, 0.35])\n",
      "('g_loss', [2.0784237, 0.6500156, 1.4284081, 0.88, 1.4284081])\n",
      "1000/1000 [==============================] - 0s 62us/step\n",
      "('c_loss:', [0.4692161784172058, 0.675])\n",
      "epoch: 2200\n",
      "('d_loss', [0.6593016, 0.76])\n",
      "('g_loss', [2.1575031, 0.75921524, 1.3982878, 0.0, 1.3982878])\n",
      "1000/1000 [==============================] - 0s 62us/step\n",
      "('c_loss:', [0.25146265053749084, 1.0])\n",
      "epoch: 2300\n",
      "('d_loss', [0.72421783, 0.5])\n",
      "('g_loss', [2.253993, 0.85259384, 1.4013991, 0.0, 1.4013991])\n",
      "1000/1000 [==============================] - 0s 64us/step\n",
      "('c_loss:', [0.42215160846710204, 0.825])\n",
      "epoch: 2400\n",
      "('d_loss', [0.65716887, 0.67])\n",
      "('g_loss', [2.2829642, 0.8827081, 1.400256, 0.0, 1.400256])\n",
      "1000/1000 [==============================] - 0s 62us/step\n",
      "('c_loss:', [0.2982688429355621, 0.984])\n",
      "epoch: 2500\n",
      "('d_loss', [0.685767, 0.435])\n",
      "('g_loss', [2.0318294, 0.6279616, 1.4038678, 1.0, 1.4038678])\n",
      "1000/1000 [==============================] - 0s 62us/step\n",
      "('c_loss:', [0.35853545379638674, 0.789])\n",
      "epoch: 2600\n",
      "('d_loss', [0.552732, 0.825])\n",
      "('g_loss', [2.119549, 0.726352, 1.3931971, 0.0, 1.3931971])\n",
      "1000/1000 [==============================] - 0s 61us/step\n",
      "('c_loss:', [0.36662230372428894, 0.784])\n",
      "epoch: 2700\n",
      "('d_loss', [0.64160067, 0.28])\n",
      "('g_loss', [2.0735598, 0.63830256, 1.4352573, 0.83, 1.4352573])\n",
      "1000/1000 [==============================] - 0s 62us/step\n",
      "('c_loss:', [0.17831354105472566, 1.0])\n",
      "epoch: 2800\n",
      "('d_loss', [0.71004546, 0.5])\n",
      "('g_loss', [2.2577038, 0.85923105, 1.3984728, 0.0, 1.3984728])\n",
      "1000/1000 [==============================] - 0s 61us/step\n",
      "('c_loss:', [0.38398686504364016, 0.838])\n",
      "epoch: 2900\n",
      "('d_loss', [0.5823926, 0.745])\n",
      "('g_loss', [2.4457984, 1.0529501, 1.3928484, 0.0, 1.3928484])\n",
      "1000/1000 [==============================] - 0s 61us/step\n",
      "('c_loss:', [0.3721672730445862, 0.777])\n",
      "epoch: 3000\n",
      "('d_loss', [0.651464, 0.645])\n",
      "('g_loss', [2.295594, 0.90289086, 1.392703, 0.0, 1.392703])\n",
      "1000/1000 [==============================] - 0s 61us/step\n",
      "('c_loss:', [0.3170924472808838, 0.972])\n",
      "epoch: 3100\n",
      "('d_loss', [0.56894416, 0.775])\n",
      "('g_loss', [2.3612921, 0.9677727, 1.3935194, 0.0, 1.3935194])\n",
      "1000/1000 [==============================] - 0s 63us/step\n",
      "('c_loss:', [0.3747235713005066, 0.803])\n",
      "epoch: 3200\n",
      "('d_loss', [0.65012133, 0.615])\n",
      "('g_loss', [2.311904, 0.91798097, 1.3939229, 0.0, 1.3939229])\n",
      "1000/1000 [==============================] - 0s 62us/step\n",
      "('c_loss:', [0.33405320703983304, 0.925])\n",
      "epoch: 3300\n",
      "('d_loss', [0.59710866, 0.695])\n",
      "('g_loss', [2.224112, 0.7998079, 1.4243042, 0.03, 1.4243042])\n",
      "1000/1000 [==============================] - 0s 62us/step\n",
      "('c_loss:', [0.20524138081073762, 1.0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3400\n",
      "('d_loss', [0.6185015, 0.755])\n",
      "('g_loss', [2.1979754, 0.7987216, 1.3992538, 0.0, 1.3992538])\n",
      "1000/1000 [==============================] - 0s 63us/step\n",
      "('c_loss:', [0.2506622346639633, 1.0])\n",
      "epoch: 3500\n",
      "('d_loss', [0.61125624, 0.735])\n",
      "('g_loss', [2.3001392, 0.9074166, 1.3927226, 0.0, 1.3927226])\n",
      "1000/1000 [==============================] - 0s 63us/step\n",
      "('c_loss:', [0.3020480636358261, 0.988])\n",
      "epoch: 3600\n",
      "('d_loss', [0.5239623, 0.755])\n",
      "('g_loss', [2.3323357, 0.94179255, 1.3905431, 0.0, 1.3905431])\n",
      "1000/1000 [==============================] - 0s 65us/step\n",
      "('c_loss:', [0.26105241930484774, 0.979])\n",
      "epoch: 3700\n",
      "('d_loss', [0.63140684, 0.685])\n",
      "('g_loss', [2.3216884, 0.92838556, 1.3933029, 0.0, 1.3933029])\n",
      "1000/1000 [==============================] - 0s 67us/step\n",
      "('c_loss:', [0.34361365461349486, 0.922])\n",
      "epoch: 3800\n",
      "('d_loss', [0.616743, 0.685])\n",
      "('g_loss', [2.3243597, 0.9293277, 1.3950319, 0.0, 1.3950319])\n",
      "1000/1000 [==============================] - 0s 63us/step\n",
      "('c_loss:', [0.37417788314819334, 0.773])\n",
      "epoch: 3900\n",
      "('d_loss', [0.67713284, 0.56])\n",
      "('g_loss', [2.299767, 0.90664923, 1.3931178, 0.0, 1.3931178])\n",
      "1000/1000 [==============================] - 0s 70us/step\n",
      "('c_loss:', [0.39975203704833984, 0.856])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-ec3b90070156>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-90-ef5d14d37ae0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mgen_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_input_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0msynthetic_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mx_combined_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlegit_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynthetic_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan = GAN()\n",
    "gan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
